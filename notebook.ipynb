{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c79454e5",
   "metadata": {},
   "source": [
    "# Тестовое задание\n",
    "Информация о данных: https://ai.stanford.edu/~amaas/data/sentiment/\n",
    "\n",
    "Короткое объяснение: требуется обучить модель на задачу классификации комментариев пользователей к фильмам, а также сделать возможным интерпретировать ответ в значения от 1 до 10 (например, звезд)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "07fc7aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Даня\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import tokenize\n",
    "\n",
    "import sklearn\n",
    "import torch\n",
    "import nltk\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e277a0a",
   "metadata": {},
   "source": [
    "# Считаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae946ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = 'data/aclImdb/train/'\n",
    "TEST_DATA_PATH = 'data/aclImdb/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "6fc62124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_txt(path):\n",
    "    comments_names = os.listdir(path)\n",
    "    if path[-4:] == 'pos/':\n",
    "        target = 1\n",
    "    else: \n",
    "        target = 0\n",
    "    comments = []\n",
    "    for comment in comments_names:\n",
    "        with open(os.path.join(path, comment) , encoding=\"utf8\") as f:\n",
    "            lines = f.readlines()\n",
    "            comments.append([lines[0], target])\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "edadfce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos = open_txt('data/aclImdb/train/pos/')\n",
    "train_neg = open_txt('data/aclImdb/train/neg/')\n",
    "test_pos = open_txt('data/aclImdb/test/pos/')\n",
    "test_neg = open_txt('data/aclImdb/test/neg/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "aa60730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#словарь\n",
    "with open('data/aclImdb/imdb.vocab', encoding=\"utf8\") as f:\n",
    "        all_words = f.readlines()\n",
    "        all_words[i] = all_words[i][:-1]\n",
    "for i in range(len(all_words)):\n",
    "    all_words[i] = all_words[i][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "021bcfff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Bromwell High is a cartoon comedy. It ran at t...       1\n",
       "1  Homelessness (or Houselessness as George Carli...       1\n",
       "2  Brilliant over-acting by Lesley Ann Warren. Be...       1"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(train_pos + train_neg, columns = ['text', 'target'])\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "875166aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a recreational golfer with some knowledge o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  I went and saw this movie last night after bei...       1\n",
       "1  Actor turned director Bill Paxton follows up h...       1\n",
       "2  As a recreational golfer with some knowledge o...       1"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame(test_pos + test_neg, columns = ['text', 'target'])\n",
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dd04be",
   "metadata": {},
   "source": [
    "# Токенизируем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "cdc9b39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_symbols = '\"!@#$%^&*():;-+?_=,<>/'\n",
    "def tokenizer_text(sent):\n",
    "    tokens = [word.lower() for word in nltk.word_tokenize(sent)]\n",
    "    tokens = [word for word in tokens if word not in pucnt_symbols]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "e271e250",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['tokenized'] = train_df['text'].apply(tokenizer_text)\n",
    "test_df['tokenized'] = test_df['text'].apply(tokenizer_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "d0f02deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, went, and, saw, this, movie, last, night, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
       "      <td>1</td>\n",
       "      <td>[actor, turned, director, bill, paxton, follow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a recreational golfer with some knowledge o...</td>\n",
       "      <td>1</td>\n",
       "      <td>[as, a, recreational, golfer, with, some, know...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, saw, this, film, in, a, sneak, preview, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bill Paxton has taken the true story of the 19...</td>\n",
       "      <td>1</td>\n",
       "      <td>[bill, paxton, has, taken, the, true, story, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>I occasionally let my kids watch this garbage ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, occasionally, let, my, kids, watch, this, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>When all we have anymore is pretty much realit...</td>\n",
       "      <td>0</td>\n",
       "      <td>[when, all, we, have, anymore, is, pretty, muc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>The basic genre is a thriller intercut with an...</td>\n",
       "      <td>0</td>\n",
       "      <td>[the, basic, genre, is, a, thriller, intercut,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>Four things intrigued me as to this film - fir...</td>\n",
       "      <td>0</td>\n",
       "      <td>[four, things, intrigued, me, as, to, this, fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>David Bryce's comments nearby are exceptionall...</td>\n",
       "      <td>0</td>\n",
       "      <td>[david, bryce, 's, comments, nearby, are, exce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target  \\\n",
       "0      I went and saw this movie last night after bei...       1   \n",
       "1      Actor turned director Bill Paxton follows up h...       1   \n",
       "2      As a recreational golfer with some knowledge o...       1   \n",
       "3      I saw this film in a sneak preview, and it is ...       1   \n",
       "4      Bill Paxton has taken the true story of the 19...       1   \n",
       "...                                                  ...     ...   \n",
       "24995  I occasionally let my kids watch this garbage ...       0   \n",
       "24996  When all we have anymore is pretty much realit...       0   \n",
       "24997  The basic genre is a thriller intercut with an...       0   \n",
       "24998  Four things intrigued me as to this film - fir...       0   \n",
       "24999  David Bryce's comments nearby are exceptionall...       0   \n",
       "\n",
       "                                               tokenized  \n",
       "0      [i, went, and, saw, this, movie, last, night, ...  \n",
       "1      [actor, turned, director, bill, paxton, follow...  \n",
       "2      [as, a, recreational, golfer, with, some, know...  \n",
       "3      [i, saw, this, film, in, a, sneak, preview, an...  \n",
       "4      [bill, paxton, has, taken, the, true, story, o...  \n",
       "...                                                  ...  \n",
       "24995  [i, occasionally, let, my, kids, watch, this, ...  \n",
       "24996  [when, all, we, have, anymore, is, pretty, muc...  \n",
       "24997  [the, basic, genre, is, a, thriller, intercut,...  \n",
       "24998  [four, things, intrigued, me, as, to, this, fi...  \n",
       "24999  [david, bryce, 's, comments, nearby, are, exce...  \n",
       "\n",
       "[25000 rows x 3 columns]"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "971ddc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(train_df['tokenized'])\n",
    "dic = dictionary.token2id\n",
    "inv_dic = {v: k for k, v in dic.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "473ef334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111703"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5bfbeb",
   "metadata": {},
   "source": [
    "# Обертка на Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "96c1a192",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecWrap:\n",
    "    def __init__(self, tokens, vec_size, window, min_count, epochs):\n",
    "        self.tokens = tokens\n",
    "        self.epochs = epochs\n",
    "        self.vec_size = vec_size\n",
    "        self.model_wv = Word2Vec(sentences=tokens,\n",
    "                                 vector_size=vec_size,\n",
    "                                 window=window,\n",
    "                                 min_count=min_count)\n",
    "\n",
    "    def train(self):\n",
    "        self.model_wv.train(tokens, total_examples=len(tokens), epochs=self.epochs)\n",
    "\n",
    "    def save(self, path):\n",
    "        self.model_wv.save(path)\n",
    "\n",
    "    def vocab(self):\n",
    "        return self.model_wv.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1715df7a",
   "metadata": {},
   "source": [
    "# Обучаем и проверяем Word2Vec\n",
    "Получать векторное представление предложения будем с помощью w2v, где эмбеддинги всех слов в предложении просто будем усреднять"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "f20a0ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wv = Word2VecWrap(train_df['tokenized'], vec_size=64, window=5, min_count=3, epochs=15)\n",
    "model_wv.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "abf2f73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42788"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_wv.vocab()) #если бы min_count = 1, то слов бы было 115к"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "61e575af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2vec_train(question, model):\n",
    "    token_question = np.array(question)\n",
    "    question_array = np.zeros(model.vec_size)\n",
    "    count = 0\n",
    "    for word in token_question:\n",
    "        if model.vocab().__contains__(str(word)):\n",
    "            question_array += (np.array(model.vocab()[str(word)]))\n",
    "            count += 1\n",
    "    if count == 0:\n",
    "        return question_array\n",
    "\n",
    "    return question_array / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "162a6102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(a, b):\n",
    "    similarity = np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "ba3163f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Косинусное расстояние между словами мама и папа: 0.9359934025562218\n",
      "Косинусное расстояние между словами мама и огонь: 0.26493216103160466\n",
      "Косинусное расстояние между pos предложениями:  0.8927138205559247\n"
     ]
    }
   ],
   "source": [
    "#Как мы видим word2vec работает, ембеддинговое пространство он построил \n",
    "mom = sent2vec_train(['mom'], model_wv)\n",
    "dad = sent2vec_train(['dad'], model_wv)\n",
    "fire = sent2vec_train(['fire'], model_wv)\n",
    "print(\"Косинусное расстояние между словами мама и папа: \", cos_sim(mom, dad), '\\n',\n",
    "     \"Косинусное расстояние между словами мама и огонь: \", cos_sim(mom, fire), sep='')\n",
    "\n",
    "pos_1 = sent2vec_train(train_df['tokenized'][100], model_wv)\n",
    "pos_2 = sent2vec_train(train_df['tokenized'][200], model_wv)\n",
    "print(\"Косинусное расстояние между pos предложениями: \", cos_sim(pos_1, pos_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df01b8e",
   "metadata": {},
   "source": [
    "# Пишем обертку на CatBoost\n",
    "Будем подавать эмбеддинги предложений в катбуст для предсказания таргета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "e2b6746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatBoostClassifierWrap:\n",
    "    def __init__(self, n_estimators, max_depth, learning_rate):\n",
    "        self.model = CatBoostClassifier(n_estimators=n_estimators,\n",
    "                                   max_depth=max_depth,\n",
    "                                   learning_rate=learning_rate,\n",
    "                                   early_stopping=50,\n",
    "                                   random_state=42,\n",
    "                                   verbose=1)\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        self.model.fit(x_train, y_train)\n",
    "\n",
    "    def save(self, path):\n",
    "        pickle.dump(self.model, open(path, \"wb\"))\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        return self.model.predict_proba(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "593d21c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_model(df):\n",
    "    X, Y = [], []\n",
    "    for sentence in range(len(df['target'])):\n",
    "        X.append(sent2vec_train(df['tokenized'][sentence], model_wv))\n",
    "        Y.append(df['target'][sentence])\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "e64c3308",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sent2vec_train(train_df['tokenized'][0], model_wv)) == 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "c1b23b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = data_to_model(train_df)\n",
    "X_test, Y_test = data_to_model(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "98fb0460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6766503\ttotal: 11.3ms\tremaining: 11.3s\n",
      "100:\tlearn: 0.4650042\ttotal: 1.03s\tremaining: 9.2s\n",
      "200:\tlearn: 0.4046956\ttotal: 2.07s\tremaining: 8.22s\n",
      "300:\tlearn: 0.3618545\ttotal: 3.11s\tremaining: 7.22s\n",
      "400:\tlearn: 0.3268324\ttotal: 4.12s\tremaining: 6.16s\n",
      "500:\tlearn: 0.2973260\ttotal: 5.14s\tremaining: 5.12s\n",
      "600:\tlearn: 0.2708515\ttotal: 6.15s\tremaining: 4.08s\n",
      "700:\tlearn: 0.2476563\ttotal: 7.16s\tremaining: 3.05s\n",
      "800:\tlearn: 0.2262150\ttotal: 8.17s\tremaining: 2.03s\n",
      "900:\tlearn: 0.2076009\ttotal: 9.19s\tremaining: 1.01s\n",
      "999:\tlearn: 0.1906062\ttotal: 10.2s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x17ed12870d0>"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cl = CatBoostClassifier(max_depth=6, learning_rate=0.10, verbose=100)\n",
    "model_cl.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "555799c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2441681, 0.7558319])"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cl.predict_proba(X_train[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9370d743",
   "metadata": {},
   "source": [
    "# Оценка результатов\n",
    "Посмотрим на accuracy, recall, precision на трейне и на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "be7c00c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9629\n",
      "Precision: 0.9651\n",
      "Recall: 0.9605\n"
     ]
    }
   ],
   "source": [
    "train_predicts = model_cl.predict(X_train)\n",
    "print('Accuracy: ', round((train_predicts == Y_train).sum() / len(Y_train), 4), '\\n',\n",
    "      'Precision: ', round(sklearn.metrics.precision_score(Y_train, train_predicts), 4), '\\n',\n",
    "      'Recall: ', round(sklearn.metrics.recall_score(Y_train, train_predicts), 4), sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "8765f0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7882\n",
      "Precision: 0.7882\n",
      "Recall: 0.7882\n"
     ]
    }
   ],
   "source": [
    "test_predicts = model_cl.predict(X_test)\n",
    "print('Accuracy: ', round((test_predicts == Y_test).sum() / len(Y_test), 4), '\\n',\n",
    "      'Precision: ', round(sklearn.metrics.precision_score(Y_test, test_predicts), 4), '\\n',\n",
    "      'Recall: ', round(sklearn.metrics.recall_score(Y_test, test_predicts), 4), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c60109",
   "metadata": {},
   "source": [
    "# Выводы, идеи, предложения\n",
    "### Это ноутбук показывает ML/DL часть, в train.py/model.py будет меньше кода, т.к. тут присутствует небольшой анализ. Оценку комментарию по итогу будем ставить смотря на вероятности, которые нам возвращает модель, то есть если вероятность pos = 0.84, то будем считать, что пользователь поставил 8/10\n",
    "### Видим, что модель переобучилась, с этим можно бороться разными способами, один из самых главных - тюнинг параметров, причем не только самого бустинга, но и w2v, размерности векторов(ее можно сжать с помощью SVD-разложения) и прочих параметров.\n",
    "### Также было неколько идей: взять трансформер с HF, взять tf-idf или doc2vec(т.к. комментарии достаточно длинные), можно было попробовать RNN и предсказывать таргет сразу одной моделью, а не как в моем решении (сначала получаем ембеддинговое представление word2vec-а, а потом передаем в catboost).\n",
    "### Вариантов очень много, можно было бы использовать даже k-means или DBSCAN, но все пробовать в данном случае смысла не имеет, это тестовое задание и один и вариантов его решения"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
